# Spark cluster on Yarn Hadoop cluster with Jupyter notebook integration

This configuration allows you to seamlessly run Python code alongside Spark, enabling powerful data processing and analysis. It combines the distributed computing 
capabilities of Spark with the flexibility and interactivity of Jupyter Notebook, making it easier to work with big data and perform data transformations, analysis, and machine learning tasks efficiently.

### Spark Master
Access: http://localhost:9090
![spark-master](https://github.com/ClementineM12/spark_hadoop_jupyter-notebooks_/assets/106354411/c34c7d6e-3f2b-4146-9e7d-388287583ffd)

### Namenode
Access: http://localhost:9870
![namenode](https://github.com/ClementineM12/spark_hadoop_jupyter-notebooks_/assets/106354411/9ce3cc9e-22eb-4eda-9eae-fafee1a83dfa)

### Jupyter notebook
Access: http://localhost:8888
![jupyter](https://github.com/ClementineM12/spark_hadoop_jupyter-notebooks_/assets/106354411/3b482bbf-76d0-4321-a5a3-ca1d5a2381be)
