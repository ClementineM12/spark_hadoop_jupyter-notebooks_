# Spark Cluster on Yarn Hadoop Cluster with Jupyter Notebook Integration

This configuration allows you to seamlessly run Python code alongside Spark, enabling powerful data processing and analysis. It combines the distributed computing capabilities 
of Spark with the flexibility and interactivity of Jupyter Notebook, making it easier to work with big data and perform data transformations, analysis, and machine learning tasks efficiently.

## Access URLs

### Spark Master
You can access the Spark Master at [http://localhost:9090](http://localhost:9090).

### Namenode
You can access the Namenode at [http://localhost:9870](http://localhost:9870).

### Jupyter Notebook
You can access Jupyter Notebook at [http://localhost:8888](http://localhost:8888).

## Getting Started

To get started with this Spark cluster on Yarn Hadoop cluster with Jupyter Notebook integration, follow these steps:

1. [Installation](#installation): Instructions for installing the necessary software components.
2. [Configuration](#configuration): Configure your cluster settings.
3. [Usage](#usage): Learn how to use the cluster effectively for your data processing needs.



